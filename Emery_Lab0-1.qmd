---
title: "Lab0"
author: "Eric Vance"
format: pdf
editor: visual
---

## **Lab0:** About Your Team, About Individuals, and Team Collaboration

**Due: 11:59PM Sunday, January 25 on Canvas as a knitted pdf file of a Quarto document**

1.  You will determine your team's name and goals.
2.  You will add to the document your individual sections.
3.  You will practice collaborating on an applied statistical learning "project."

### Instructions for Lab0

1.  Using Quarto, you will complete the first team section "About Team Teamname." See further instructions below.
2.  Each team member will add their own individual section to the team Quarto document. How do you want to collaborate on your document this semester? Github? Google Colab? Something else? See instructions for individual sections below.
3.  As a team, you will complete an applied "project". There will be some individual components (so that everyone gets practice with implementing the stat learning methods) and team components.

### About Your Team

In this team section, include a team photo (all of you), your team name, and your teamâ€™s main goal for this semester for this course (i.e., what does your team want to accomplish by the end of the semester?). Throughout the semester you will be giving feedback to your teammates about how well they are helping your team accomplish its goal(s).

#### Individual Sections

Each individual must complete their own subsection, which must include:

-   a photo of yourself with a caption explaining the context
-   at least one (non-statistics) question you would like to know the answer to that could potentially be answered by applying statistical learning methods to data
-   what you would love to be doing six months after graduation and then five years after that (what would make you excited to be doing?)
-   what you hope your greatest career accomplishment will be
-   and given these hopes and goals, what you are hoping to learn/accomplish/do in this course.
-   You must also include something of your own choosing not described above. Anything. Be creative!

### Team Applied Section

Find the misclassification rate for K-nearest neighbors (KNN) for a range of k values, given a complicated true generating model. Do this individually. As a team, compare answers and then plot the decision boundary for the team's "best" value of k.

Also, individually practice walking through the steps of Q1, Q2, and Q3 for this "project". Within this section will be a team section (what is the "best" k and what is the decision boundary) and individual sections. In your individual section, describe a plausible story for Q1, Q2, and Q3. Specifically, for Q1: What is Y, X1, and X2, and why should we care?. Make up something plausible that you actually care about. Y could be whether a kitten is adopted from a shelter given X1=age and X2=health of the cat. That's just one of countless plausible examples.

For Q2: Make predictions given X1 and X2 using KNN and k=(1 and 5) or (2 and 6) or (3 and 7) or (4 and 8). That is, each teammate fits KNN for two different values of k. Compute the misclassification rates for your values of k.

For Q3: Using this model and your plausible Q1 scenario, what is the answer for X1=0.5 and X2=0.5? For your scenario, what are some ethical implications of your stat learning modeling?

#### Generating Model

We have a logistic regression generating model. Given $x_1 \in [0,1]$ and $x_2 \in [0,1], Y \sim Ber(p)$, where $p$ is related to $x_1$ and $x_2$ through the logistic link function: $\log(\frac{p}{(1-p)}) = x_1 -2x_2 -2{x_1}^{2} + {x_2}^{2} + 3{x_1}{x_2}$, where $\log$ is the natural log, sometimes written as $\ln$.

The code for this is below.

```{r}
library(class)
library(tidyverse)
```

```{r}
#Generative model
set.seed(116) #setting a random seed so that we can reproduce everything exactly if we want to

generate_y <- function(x1,x2) { #two input parameters to generate the output y
  logit <- x1 -2*x2 -2*x1^2 + x2^2 + 3*x1*x2
  p <- exp(logit)/(1+exp(logit)) #apply the inverse logit function
  y <- rbinom(1,1,p) #y becomes a 0 (with prob 1-p) or a 1 with probability p
}
```

#### Example code

We are going to use our generating model to create a test set of 100 predictors (x1, x2), and then 100 outcomes. Then we plot all three variables just to see what the generating model is doing.

```{r}
# Generate a dataset with 100 points
set.seed(116)
n = 100
X1 <- runif(n,0,1)
X2 <- runif(n,0,1)

#I'm going to use a for loop to generate 100 y's
Y <- rep(0,n) #initializing my Y to be a vector of 0's
for (i in 1:n) {
  Y[i] <- generate_y(X1[i],X2[i])
}

sum(Y) #How many 0's and 1's were predicted? In this training set, 42% were 1's. However, almost 48% are 1's when n is large. That's quite close to 50/50 so we shouldn't have issues with "imbalance," which is something we'll learn about later in the semester.

training <- cbind(X1,X2,Y) #combining all of my variables into a training dataset
ggplot(data=training, aes(x=X1, y=X2, color=Y)) +
  geom_point()
```

This generating function seems to produce Y's with some spatial pattern in the X1, X2 parameter space, but the regions of 0's and 1's are not very well separated. How well will KNN do to classify/predict Y given new x1 and x2 values?

#### Test dataset

We are going to generate a new set of 100 predictors (x1, x2) and outcomes (y) that we will use as our "ground truth".

So, create the test dataset (using random seed=121) first.

```{r}
# Create the training dataset as above using seed=116
# Create a testing dataset using seed=121

set.seed(121)
n = 100
X1 <- runif(n,0,1)
X2 <- runif(n,0,1)

#I'm going to use a for loop to generate 100 y's
Y <- rep(0,n) #initializing my Y to be a vector of 0's
for (i in 1:n) {
  Y[i] <- generate_y(X1[i],X2[i])
}

sum(Y) #43 1's, which is much closer to the 51.5% true rate
testing <- cbind(X1,X2,Y)

#Let's plot the test set. Does it look like the training set? Yeah, looks similar.
ggplot(data=testing, aes(x=X1, y=X2, color=Y)) +
  geom_point()
```

#### What individuals need to do

1.  Given the training set (seed=116) and the testing set (seed=121), fit KNN on two different values of k.

    ```{r}
    train_X <- training[,1:2]
    test_X  <- testing[,1:2]
    train_Y <- training[,3]


    KNN_k4 <- knn(train = train_X, test = test_X, cl = train_Y, k = 4)
    KNN_k8 <- knn(train = train_X, test = test_X, cl = train_Y, k = 8)

    ```

2.  Calculate the misclassification rate for each k. If you don't know how to do this, ask a teammate or the professor.

    ```{r}
    true_Y <- testing[,3]

    misclass_rate <- function(predictions, test.truth) { #Given the model predictions and the true classifications
      1-(sum(predictions==test.truth)/length(predictions))
    }

    misclass_rate(KNN_k4, true_Y)
    misclass_rate(KNN_k8, true_Y)
    ```

3.  If possible, plot the decision boundaries for your k values.

    ```{r}
    # 1. Setup the Grid correctly
    # Ensure the grid names match your training column names (X1, X2)
    testing.grid <- expand.grid(X1 = seq(0, 1, by = .01), 
                                X2 = seq(0, 1, by = .01))

    # 2. Run KNN on the grid
    # We convert the output to numeric so geom_contour can read it
    predicted.grid.4 <- knn(train = train_X, 
                          test = testing.grid, 
                          cl = train_Y, 
                          k = 4)
    predicted.grid.8 <- knn(train = train_X, 
                            test = testing.grid,
                            cl = train_Y,
                            k = 8)

    # 3. Combine grid coordinates with predictions
    predicted.gridxy.4 <- testing.grid
    predicted.gridxy.4$Y <- as.numeric(predicted.grid.4) -1  

    predicted.gridxy.8 <- testing.grid
    predicted.gridxy.8$Y <- as.numeric(predicted.grid.8) -1


    # Plotting K=4
    ggplot() +
      # Background: Show the decision regions
      geom_raster(data = predicted.gridxy.4, aes(x = X1, y = X2, fill = as.factor(Y)), alpha = 0.5) +
      # The Boundary: The contour line where Y changes
      geom_contour(data = predicted.gridxy.4, aes(x = X1, y = X2, z = Y), 
                   breaks = 1.5, color = "black", size = 0.5) +
      # The actual data points
      geom_point(data = training, aes(x = X1, y = X2, color = as.factor(Y))) +
      scale_fill_manual(values = c("hotpink", "lightskyblue"), name = "Region") +
      scale_color_manual(values = c("hotpink4", "royalblue"), name = "Actual Class") +
      labs(title = "KNN Decision Boundary (k=4)",
           subtitle = "Black line indicates the Bayes-style decision boundary") +
       geom_contour(data = predicted.gridxy.4, aes(x = X1, y = X2, z = Y +1),  
                   breaks = 1.5, color = "black", size = 0.5) + # Add 1 to Y to make the contours actually plot. I don't know why the black boundary won't plot if z is 0 or 1.
    theme_minimal()

    #Plotting K=8
    ggplot() +
      # Background: Show the decision regions
      geom_raster(data = predicted.gridxy.8, aes(x = X1, y = X2, fill = as.factor(Y)), alpha = 0.5) +
      # The Boundary: The contour line where Y changes
      geom_contour(data = predicted.gridxy.8, aes(x = X1, y = X2, z = Y), 
                   breaks = 1.5, color = "black", size = 0.5) +
      # The actual data points
      geom_point(data = training, aes(x = X1, y = X2, color = as.factor(Y))) +
      scale_fill_manual(values = c("hotpink", "lightskyblue"), name = "Region") +
      scale_color_manual(values = c("hotpink4", "royalblue"), name = "Actual Class") +
      labs(title = "KNN Decision Boundary (k=8)",
           subtitle = "Black line indicates the Bayes-style decision boundary") +
       geom_contour(data = predicted.gridxy.8, aes(x = X1, y = X2, z = Y +1),  
                   breaks = 1.5, color = "black", size = 0.5) + # Add 1 to Y to make the contours actually plot. I don't know why the black boundary won't plot if z is 0 or 1.
    theme_minimal()



    ```

4.  Summarize the Q1, Q2, and Q3 aspects of this "project." Use your imagination. Everyone should have a different scenario.

5.  Think about and discuss with your team some of the bonus questions below.

#### What teams need to do

1.  Find the best k. Plot the decision boundary for that k.

2.  Answer as many of the bonus questions as you can.

#### Bonus questions

Ultimately, we would like to know more about this problem, but we don't necessarily have all the tools yet to answer all of our questions. Here are some bonus questions:

-   What is the misclassification rate for k=1...2j, where j is the "optimal" k. That is, for a whole range of k values?
-   What is the Bayes decision boundary for the optimal k?
-   How is the misclassification rate broken down into variance, bias, and irreducible error of the KNN estimator? Related to these questions are how the misclassification rate changes when we use different training or test sets.
-   What happens to the misclassification rate if we go outside the $[0,1]^2$ parameter space? I.e., if $x_1$ and $x_2$ are $<0$ or $>1$?

**Note: the intended audience for your team document is your teammates, the professor, and your future self.**

**Some intended outcomes from this assignment:**

-   You and your team will learn how to effectively edit a document collaboratively
-   You will think about what you want to accomplish in life and how this course relates to that
-   Your teammates, the professor, and the TA will learn something more about you
-   You will get more experience applying statistical learning methods
-   You will gain experience collaborating with your teammates on an applied problem
-   Get practice evaluating a method, specifically KNN
-   Practice thinking about the whole problem (i.e., Q1Q2Q3, not just the Q2 quantitative parts)
